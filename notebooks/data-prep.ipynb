{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import dvc.api\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> <Logger dataCleaner (WARNING)>\n",
      "logger <Logger dataCleaner (INFO)> created at path: ../logs/cleaner_root.log\n",
      "Data cleaner in action\n",
      "--> <Logger dataVisualizer (WARNING)>\n",
      "logger <Logger dataVisualizer (INFO)> created at path: ../logs/visualizer_root.log\n",
      "Data visualizer in action\n"
     ]
    }
   ],
   "source": [
    "# adding scripts\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "sys.path.insert(1, '../scripts/')\n",
    "import defaults as defs\n",
    "import dataCleaner as dc\n",
    "import dataVisualizer as dv\n",
    "\n",
    "cleaner = dc.dataCleaner('data preparation notebook')\n",
    "visualizer = dv.dataVisualizer('data preparation notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas settings\n",
    "pd.set_option('display.max_columns', 30)\n",
    "\n",
    "# version of the data\n",
    "# v1 : gdrive \n",
    "# v2 : local messed up store\n",
    "# v3 : local correct store\n",
    "version = 'v3'\n",
    "\n",
    "# read data sets using dvc api\n",
    "test_data_url = dvc.api.get_url(path = defs.test_local_path, \n",
    "                                repo = defs.repo, \n",
    "                                rev = version)\n",
    "\n",
    "train_data_url = dvc.api.get_url(path = defs.train_local_path, \n",
    "                                repo = defs.repo, \n",
    "                                rev = version)\n",
    "\n",
    "store_data_url = dvc.api.get_url(path = defs.store_local_path, \n",
    "                                repo = defs.repo, \n",
    "                                rev = version)\n",
    "# print('test data path: ' + test_data_url, '\\ntrain data path: ' + train_data_url, '\\nstore data path: ' + store_data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading csv files\n",
    "DateCols = ['Date']\n",
    "missing_values = [\"n/a\", \"na\", \"undefined\", '?', 'NA', 'undefined']\n",
    "\n",
    "\"\"\"test_data = pd.read_csv(io.StringIO(test_data_url), na_values=missing_values, parse_dates=DateCols, low_memory=False)\n",
    "train_data = pd.read_csv(io.StringIO(train_data_url), na_values=missing_values, parse_dates=DateCols, low_memory=False)\n",
    "store_data = pd.read_csv(io.StringIO(store_data_url), na_values=missing_values, low_memory=False)\"\"\"\n",
    "\n",
    "test_data = pd.read_csv(test_data_url, na_values=missing_values, parse_dates=DateCols, low_memory=False)\n",
    "train_data = pd.read_csv(train_data_url, na_values=missing_values, parse_dates=DateCols, low_memory=False)\n",
    "store_data = pd.read_csv(store_data_url, na_values=missing_values, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1017209 entries, 0 to 1017208\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count    Dtype         \n",
      "---  ------         --------------    -----         \n",
      " 0   Store          1017209 non-null  int64         \n",
      " 1   DayOfWeek      1017209 non-null  int64         \n",
      " 2   Date           1017209 non-null  datetime64[ns]\n",
      " 3   Sales          1017209 non-null  int64         \n",
      " 4   Customers      1017209 non-null  int64         \n",
      " 5   Open           1017209 non-null  int64         \n",
      " 6   Promo          1017209 non-null  int64         \n",
      " 7   StateHoliday   1017209 non-null  object        \n",
      " 8   SchoolHoliday  1017209 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(7), object(1)\n",
      "memory usage: 69.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41088 entries, 0 to 41087\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   Id             41088 non-null  int64         \n",
      " 1   Store          41088 non-null  int64         \n",
      " 2   DayOfWeek      41088 non-null  int64         \n",
      " 3   Date           41088 non-null  datetime64[ns]\n",
      " 4   Open           41077 non-null  float64       \n",
      " 5   Promo          41088 non-null  int64         \n",
      " 6   StateHoliday   41088 non-null  object        \n",
      " 7   SchoolHoliday  41088 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(5), object(1)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1115 entries, 0 to 1114\n",
      "Data columns (total 10 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Store                      1115 non-null   int64  \n",
      " 1   StoreType                  1115 non-null   object \n",
      " 2   Assortment                 1115 non-null   object \n",
      " 3   CompetitionDistance        1112 non-null   float64\n",
      " 4   CompetitionOpenSinceMonth  761 non-null    float64\n",
      " 5   CompetitionOpenSinceYear   761 non-null    float64\n",
      " 6   Promo2                     1115 non-null   int64  \n",
      " 7   Promo2SinceWeek            571 non-null    float64\n",
      " 8   Promo2SinceYear            571 non-null    float64\n",
      " 9   PromoInterval              571 non-null    object \n",
      "dtypes: float64(5), int64(2), object(3)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "store_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 0.0 % missing values\n",
      "The dataset contains 0.0033464759 % missing values\n",
      "The dataset contains 21.0134529148 % missing values\n"
     ]
    }
   ],
   "source": [
    "cleaner.percent_missing(train_data)\n",
    "cleaner.percent_missing(test_data)\n",
    "cleaner.percent_missing(store_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize missing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df = cleaner.missing_values_table(store_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data[missing_df.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Store data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filing the competition distance feature\n",
    "max_dist = store_data['CompetitionDistance'].max()\n",
    "cleaner.fix_missing_value(store_data, ['CompetitionDistance'], max_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the competition open since year and month features\n",
    "min_year = store_data['CompetitionOpenSinceYear'].min()\n",
    "cleaner.fix_missing_value(store_data, ['CompetitionOpenSinceYear'], min_year)\n",
    "cleaner.fix_missing_value(store_data, ['CompetitionOpenSinceMonth'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the promo2since week and year features\n",
    "cleaner.fix_missing_value(store_data, ['Promo2SinceWeek', 'Promo2SinceYear'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the promo interval feature\n",
    "cleaner.fix_missing_value(store_data, ['PromoInterval'], '0,0,0,0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_mean = test_data['Open'].mean()\n",
    "cleaner.fix_missing_value(test_data, ['Open'], open_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final check for missing values\n",
    "cleaner.percent_missing(train_data)\n",
    "cleaner.percent_missing(test_data)\n",
    "cleaner.percent_missing(store_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the object data types to string\n",
    "string_columns = ['StoreType', 'Assortment']\n",
    "store_data = cleaner.convert_to_string(store_data, string_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the float data types to int\n",
    "float_columns = store_data.select_dtypes(include='float').columns.tolist()\n",
    "store_data = cleaner.convert_to_int(store_data, float_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  convert string types to int\n",
    "store_data = cleaner.encode_to_numeric(store_data, ['StoreType', 'Assortment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert float to int\n",
    "store_data = cleaner.convert_to_int(store_data, ['CompetitionDistance', 'CompetitionOpenSinceMonth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['StateHoliday'].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the state holiday feature data type from mixed to string\n",
    "train_data = cleaner.convert_to_string(train_data, ['StateHoliday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the string datatype to int\n",
    "train_data = cleaner.encode_to_numeric(train_data, ['StateHoliday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert float to int\n",
    "train_data = cleaner.convert_to_int(train_data, ['Sales', 'Customers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change object data type to string\n",
    "test_data = cleaner.convert_to_string(test_data, ['StateHoliday'])\n",
    "test_data = cleaner.encode_to_numeric(test_data, ['StateHoliday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change float to int\n",
    "test_data = cleaner.convert_to_int(test_data, ['Open'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for duplicate rows and drop them\n",
    "cleaner.drop_duplicates(train_data)\n",
    "cleaner.drop_duplicates(test_data)\n",
    "cleaner.drop_duplicates(store_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a265634967a27dd555e8346f2355ee703e655fd7f0a0d20c168527cd0a3d5707"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
